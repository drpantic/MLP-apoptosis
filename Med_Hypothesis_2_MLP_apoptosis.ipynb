{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oj9M3Lm7sPB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    f1_score, roc_auc_score, precision_score, recall_score,\n",
        "    confusion_matrix, classification_report, matthews_corrcoef, roc_curve, auc\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class DropoutMLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layer_sizes, dropout_prob=0.2):\n",
        "        super(DropoutMLPClassifier, self).__init__()\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "        for size in hidden_layer_sizes:\n",
        "            layers.append(nn.Linear(prev_size, size))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(p=dropout_prob))\n",
        "            prev_size = size\n",
        "        layers.append(nn.Linear(prev_size, 1))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.network(x))\n",
        "\n",
        "def load_data_from_excel(file_path):\n",
        "    df = pd.read_excel(file_path)\n",
        "    X = df.iloc[:, :-1].values\n",
        "    y = df.iloc[:, -1].values  # (0 for intact cells, 1 for apoptotic cells)\n",
        "    return X, y\n",
        "\n",
        "file_path = 'path_to_your_file.xlsx'  # This part of the code enables the use of MS Excel file\n",
        "X, y = load_data_from_excel(file_path)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('mlp', MLPClassifier(max_iter=500, random_state=42, early_stopping=True))\n",
        "])\n",
        "\n",
        "param_space = {\n",
        "    'mlp__hidden_layer_sizes': [(50, 50), (100, 50), (100, 100)],\n",
        "    'mlp__activation': ['tanh', 'relu'],\n",
        "    'mlp__solver': ['adam', 'lbfgs'],\n",
        "    'mlp__alpha': Real(1e-5, 1e-2, prior='log-uniform'),\n",
        "    'mlp__learning_rate_init': Real(1e-4, 1e-1, prior='log-uniform'),\n",
        "    'mlp__beta_1': Real(0.8, 0.999),\n",
        "    'mlp__beta_2': Real(0.9, 0.999),\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "bayes_search = BayesSearchCV(pipe, param_space, cv=cv, n_iter=32, scoring='f1', n_jobs=-1, verbose=2, random_state=42)\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = bayes_search.predict(X_test)\n",
        "y_prob = bayes_search.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"ROC AUC: {roc_auc}\")\n",
        "print(f\"MCC: {mcc}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "print(\"The Best Hyperparameters are:\")\n",
        "print(bayes_search.best_params_)\n"
      ]
    }
  ]
}